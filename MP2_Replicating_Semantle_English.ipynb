{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i3m9JjeM5U5"
      },
      "source": [
        "# **Mini-Project \\#2: Replicating Semantle**\n",
        "\n",
        "Names: Balingit, Andrei Luis & Burayag, Ethan Axl\n",
        "\n",
        "More information on the assessment is found in our Canvas course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_nSJE0QMBLk"
      },
      "source": [
        "# **Environment Setup**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR5OwW87RXKW"
      },
      "source": [
        "This code block installs all the necessary libraries for the Semantle replication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rPLB1eVMF8u",
        "outputId": "00f44b04-bd19-4161-ab9e-dbafef40c86a"
      },
      "outputs": [],
      "source": [
        "!pip install gensim fasttext numpy --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxtmCAZwNoeU"
      },
      "source": [
        "# **Load Pre-Trained Word Embeddings**\n",
        "\n",
        "This code block loads the pre-trained word embeddings to be used for the Semantle replication later on. The word embedding model to be used is either the GloVe that was trained on Wikipedia and Gigaword or another one that was trained on Twitter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jrhiQNYiV3Q4"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j2aVqIFVV6Ig"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 252.1/252.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# Comment out the word embedding model to be used\n",
        "\n",
        "# GloVe (Stanford) - Trained on Wikipedia/Gigaword\n",
        "model = api.load(\"glove-wiki-gigaword-200\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6d_xdwd5V6Qi"
      },
      "outputs": [],
      "source": [
        "# Comment out the word embedding model to be used\n",
        "\n",
        "# GloVe (Stanford) - Trained on Twitter\n",
        "# model = api.load(\"glove-twitter-200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzMTI7A_RsDl"
      },
      "source": [
        "# **Word Pool Definition & Filtering**\n",
        "This code block gets a list of standard and real English words, which will be the basis for the target words later on. This will also keep only the ones existing in our word embedding model and are long enough to be a reasonable target word. This provides a much cleaner and more realistic vocabulary for the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCcp3MvXSZUt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Word Pool Size: 98280\n"
          ]
        }
      ],
      "source": [
        "# Downloads the standard English word list\n",
        "!wget https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt --quiet\n",
        "\n",
        "# Builds the valid English word pool\n",
        "with open('words_alpha.txt') as f:\n",
        "    english_words = set(f.read().split())\n",
        "\n",
        "valid_words = [\n",
        "    word for word in english_words\n",
        "    if word in model.key_to_index\n",
        "    and len(word) > 3\n",
        "]\n",
        "\n",
        "print(f\"Valid Word Pool Size: {len(valid_words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyn4_h6OX2py"
      },
      "source": [
        "# **Target Word Selection & Cosine Similarity Calculation**\n",
        "This code block selects a random target word from the defined list of valid words. This will also calculate the cosine similarities between the target word and all other words in the word embedding model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2fvkbQ_cY5TG"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Selects a random target word to be used\n",
        "target_word = random.choice(valid_words)\n",
        "\n",
        "# Gets the cosine similarities between the target word and all words in the model\n",
        "similarities = model.most_similar(target_word, topn=len(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8YCZLi-N0uR"
      },
      "source": [
        "# **Semantle Game Replication**\n",
        "\n",
        "This code block shows and demonstrates the implementation of the replication of the Semantle Game.\n",
        "\n",
        "**Note: User Play Star Here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_kdLHWyfbXjs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "*===============================*\n",
            "           SEMANTLE              \n",
            "*===============================*\n",
            "\n",
            "Target Word: subjection\n",
            "\n",
            "Nearest Words & Similarity Scores:\n",
            "  10. - veiling 0.45311\n",
            "  100. - francoism 0.38054\n",
            "  1000. - luminiferous 0.32043\n",
            "\n",
            "*----- Your Guesses So Far -----*\n",
            "No guesses yet.\n",
            "\n",
            "*===============================*\n",
            "           SEMANTLE              \n",
            "*===============================*\n",
            "\n",
            "Target Word: subjection\n",
            "\n",
            "Nearest Words & Similarity Scores:\n",
            "  10. - veiling 0.45311\n",
            "  100. - francoism 0.38054\n",
            "  1000. - luminiferous 0.32043\n",
            "\n",
            "*----- Your Guesses So Far -----*\n",
            "  1. hat - -0.09685\n",
            "\n",
            ">>> 'hat' has a similarity score of -0.09685\n",
            "\n",
            "*===============================*\n",
            "           SEMANTLE              \n",
            "*===============================*\n",
            "\n",
            "Target Word: subjection\n",
            "\n",
            "Nearest Words & Similarity Scores:\n",
            "  10. - veiling 0.45311\n",
            "  100. - francoism 0.38054\n",
            "  1000. - luminiferous 0.32043\n",
            "\n",
            "*----- Your Guesses So Far -----*\n",
            "  1. subject - -0.01682\n",
            "  2. hat - -0.09685\n",
            "\n",
            ">>> 'subject' has a similarity score of -0.01682\n",
            "\n",
            "*===============================*\n",
            "           SEMANTLE              \n",
            "*===============================*\n",
            "\n",
            "Target Word: subjection\n",
            "\n",
            "Nearest Words & Similarity Scores:\n",
            "  10. - veiling 0.45311\n",
            "  100. - francoism 0.38054\n",
            "  1000. - luminiferous 0.32043\n",
            "\n",
            "*----- Your Guesses So Far -----*\n",
            "  1. subjugation - 0.51670\n",
            "  2. subject - -0.01682\n",
            "  3. hat - -0.09685\n",
            "\n",
            ">>> 'subjugation' has a similarity score of 0.51670\n",
            "\n",
            "*===============================*\n",
            "           SEMANTLE              \n",
            "*===============================*\n",
            "\n",
            "Great job! You guessed the word 'subjection' in 4 guess(es)!\n",
            "\n",
            "*----- Final Guesses -----*\n",
            "  1. subjection - 1.00000\n",
            "  2. subjugation - 0.51670\n",
            "  3. subject - -0.01682\n",
            "  4. hat - -0.09685\n"
          ]
        }
      ],
      "source": [
        "def print_header():\n",
        "    print(\"\\n*===============================*\")\n",
        "    print(\"           SEMANTLE              \")\n",
        "    print(\"*===============================*\\n\")\n",
        "\n",
        "end_game = False\n",
        "guesses = []\n",
        "message = \"\"\n",
        "\n",
        "while not end_game:\n",
        "\n",
        "    print_header()\n",
        "    print(f\"Target Word: {target_word}\\n\")\n",
        "    print(\"Nearest Words & Similarity Scores:\")\n",
        "    print(f\"  10. - {similarities[9][0]} {similarities[9][1]:.5f}\")\n",
        "    print(f\"  100. - {similarities[99][0]} {similarities[99][1]:.5f}\")\n",
        "    print(f\"  1000. - {similarities[999][0]} {similarities[999][1]:.5f}\")\n",
        "\n",
        "    print(\"\\n*----- Your Guesses So Far -----*\")\n",
        "    if len(guesses) == 0:\n",
        "        print(\"No guesses yet.\")\n",
        "    else:\n",
        "        for rank, (word, score) in enumerate(guesses, start=1):\n",
        "            print(f\"  {rank}. {word} - {score:.5f}\")\n",
        "\n",
        "    if message:\n",
        "        print(f\"\\n>>> {message}\")\n",
        "        message = \"\"\n",
        "\n",
        "    guess_word = input(\"\\nYour guess (Enter 1 to Exit): \").strip().lower()\n",
        "\n",
        "    if guess_word == \"1\":\n",
        "        print_header()\n",
        "        print(f\"Better luck next time! The word was '{target_word}' after {len(guesses)} guess(es)!\")\n",
        "        print(\"\\n*----- Final Guesses -----*\")\n",
        "        if len(guesses) == 0:\n",
        "            print(\"No guesses.\")\n",
        "        else:\n",
        "            for rank, (word, score) in enumerate(guesses, start=1):\n",
        "                print(f\"  {rank}. {word} - {score:.5f}\")\n",
        "        end_game = True\n",
        "        continue\n",
        "\n",
        "    if guess_word not in model.key_to_index:\n",
        "        message = f\"'{guess_word}' is not recognized in the resource. Try another word.\"\n",
        "        continue\n",
        "\n",
        "    if any(word == guess_word for word, score in guesses):\n",
        "        message = f\"You've already guessed '{guess_word}'! Try a different word.\"\n",
        "        continue\n",
        "\n",
        "    similarity_score = model.similarity(target_word, guess_word)\n",
        "    guesses.append((guess_word, similarity_score))\n",
        "    guesses.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    if guess_word == target_word:\n",
        "        print_header()\n",
        "        print(f\"Great job! You guessed the word '{target_word}' in {len(guesses)} guess(es)!\")\n",
        "        print(\"\\n*----- Final Guesses -----*\")\n",
        "        for rank, (word, score) in enumerate(guesses, start=1):\n",
        "            print(f\"  {rank}. {word} - {score:.5f}\")\n",
        "        end_game = True\n",
        "    else:\n",
        "        message = f\"'{guess_word}' has a similarity score of {similarity_score:.5f}\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conda_thesis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
